<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Project List</title>
    <link
      href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css"
      rel="stylesheet"
    />
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js"></script>
    <script
      src="https://code.jquery.com/jquery-3.2.1.min.js"
      integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
      crossorigin="anonymous"
    ></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tether/1.4.0/js/tether.min.js"></script>
    <script
      src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/js/bootstrap.min.js"
      integrity="sha384-vBWWzlZJ8ea9aCX4pEW3rVHjgjt7zpkNpZk+02D9phzyeVkE+jo0ieGizqPLForn"
      crossorigin="anonymous"
    ></script>
    <link
      href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,700"
      rel="stylesheet"
    />
    <link
      href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/css/bootstrap.min.css"
      rel="stylesheet"
      integrity="sha384-rwoIResjU2yc3z8GV/NPeZWAv56rSmLldC3R/AZzGRnGxQQKnKkoFVhFQhNUwEyJ"
      crossorigin="anonymous"
    />
    <link rel="stylesheet" href="style.css" />
  </head>
  <body>
    <div class="nd-pageheader">
      <div class="container">
        <h1>Project List</h1>
        <h5><a href="https://baulab.info">Back to main page</a></h5>
      </div>
    </div>
    <div class="container"><input class="collapse" type="checkbox" />
      <p><img src="/sliderspace.png" class="projpic" /><a href="https://sliderspace.baulab.info/">Sliderspace</a>
        Text-to-image diffusion models can create infinite diverse images from a single prompt, but we don't really understand how they organize their creative knowledge.
Until now, users had to discover interesting creative variations through trial and error - tweaking text descriptions, combining different styles, or referencing other images.
This process relies heavily on user creativity rather than understanding what the model actually knows about different concepts.

        <span class="more"></span>
        <span class="extra"> We introduce SliderSpace - a way to unlock the creative potential of diffusion models.
Instead of requiring users to find creative directions, SliderSpace automatically discovers them from the model's knowledge.
Given a concept prompt like "toy", SliderSpace identifies the key visual variations the model knows about it and turns them into simple sliders.
No need to tell it what to look for - SliderSpace finds these creative controls on its own.
 </span><a href="https://arxiv.org/pdf/2502.01639">R Gandikota, Z Wu, R Zhang, <span class="me">D Bau</span>, E Shechtman, N Kolkin.
          <em>SliderSpace: Decomposing the Visual Capabilities of Diffusion Models</em>. 
          <nobr>ICCV 2025.</nobr></a></p><input class="collapse" type="checkbox" />
      <p><a href="https://dcm.baulab.info/">Discovering Variable Binding Circuitry</a>
        Many approaches for identifying causal model components rely on brute-force activation patching, a method that is both slow and inefficient.
Moreover, these methods often fall short in identifying components that collaborate to generate a desired output.
In this paper, we introduce a technique for automatically identifying causal model components through optimization over an intervention.
We establish a set of desiderata, representing the causal attributes of the model components involved in the specific task.

        <span class="more"></span>
        <span class="extra">  </span><a href="https://arxiv.org/pdf/2307.03637.pdf">X Davies, M Nadeau, N Prakash, T R Shaham, <span class="me">D Bau</span>.
          <em>Discovering Variable Binding Circuitry with Desiderata</em>. 
          <nobr>Presented in Challenges of Deploying Generative AI Workshop at ICML 2023.</nobr></a></p><input class="collapse" type="checkbox" />
      <p><a href="https://elm.baulab.info/">Erasure of Language Memory</a>
        When erasing a piece of knowledge from language model, it is easy to destroy the model or not erase anything at all.
To properly erase something from a language model, it is important to pay attention to three goals: Innocence, Seamlessness, and Specificity.
Innocence: the erased model should not exhibit any traces of knowledge.
Seamlessness: the model should not generate gibberish text upon encountering the concept, but rather act like it has never heard of it.
Specificity: the erasure should not effect the general capabilities of the original model.
We introduce a new method called Erasure of Language Memory (ELM).
ELM stands apart from previous approaches because it addresses all the three at the same time.

        <span class="more"></span>
        <span class="extra">  </span><a href="https://arxiv.org/pdf/2410.02760">R Gandikota, S Feucht, S Marks, <span class="me">D Bau</span>.
          <em>Erasing Conceptual Knowledge from Language Models</em>. 
          <nobr>NeurIPS 2025.</nobr></a></p><input class="collapse" type="checkbox" />
      <p><img src="/erasing.png" class="projpic" /><a href="https://erasing.baulab.info/">Erasing Concepts from Diffusion Models</a>
        With recent advancements in image generation quality, there is a growing concern around safety, privacy and copyrighted content in diffusion-model-generated images.
Recent works attempt to restrict undesired content via inference methods or post-generation classification, but such methods can be easily circumvented when users have access to open-source weights.

        <span class="more"></span>
        <span class="extra"> In this paper, we propose a method for fine-tuning model weights to erase concepts from diffusion models using their own knowledge.
Given just the text of the concept to be erased, our method can edit the model weights to erase the concept while minimizing the inteference with other concepts.
This type of fine-tuning has an advantage over previous methods: it is not easy to circumvent because it modifies weights, yet it is fast and practical because it avoids the expense of retraining the whole model on filtered training data.
 </span><a href="https://arxiv.org/pdf/2303.07345.pdf">R Gandikota, J Materzyńska, J Fiotto-Kaufman, <span class="me">D Bau</span>.
          <nobr>ICCV 2023.</nobr></a></p><input class="collapse" type="checkbox" />
      <p><img src="/conceptsliders.png" class="projpic" /><a href="https://sliders.baulab.info/">Concept Sliders.</a>
        While GANs are famous for containing disenangled latents that can
control a variety of interpretable image attributes, it has not been
known whether similar controllable latents are present in diffusion
models. In this work, we develop Concept Sliders, a way of finding LoRA
adjustments to diffusion model weights that cleanly and smoothly control
a single disentangled concept. With Concept Sliders, an artist can
easily modulate a single attribute like "age" or "smiling" or even
"cooked food" to smoothly adjust the visual characteristics of an image.

        <span class="more"></span>
        <span class="extra"> Concept sliders are based on the guided-training technique underling
our previous <a href="https://erasing.baulab.info">ESD</a> work, but
instead of erasing a concept, we develop the needed techniques to
modulate or amplify a concept without changing the underlying layout
of the image, and without entangling the concept with correlated
concepts that we wish to remain unchanged. Concept sliders have been
an open-source hit among the artistic community, and they also provide
a promising window into the organization of visual concept information
within the parameter space of diffusion models. The paper develops and
evaluates over 50 different concept sliders including very interesting
sliders that reduce visible distortions in diffusion model output, and
examines their efficacy, specificity, and composability.
 </span><a href="https://arxiv.org/abs/2311.12092">R Gandikota, J Materzyńska, T Zhou, A Torralba, <span class="me">D Bau</span>.
          <em>Concept Sliders: LoRA Adaptors for Precise Control in Diffusion Models</em>. 
          <nobr>ECCV 2024.</nobr></a></p></div>
    <script>
      $(document).on("click", ".more, input.collapse + p", function (ev) {
        // Do not collapse a card if the click is for a hyperlink or selection.
        if (
          $(ev.target).closest("a").length ||
          getSelection().type == "Range" ||
          ev.shiftKey ||
          ev.ctrlKey
        ) {
          return;
        }
        // Use the hidden checkbox technique to preserve collapse-state on "back"
        var collapse = $(this).closest("p").prev("input.collapse");
        collapse.prop("checked", !collapse.prop("checked"));
        ev.stopPropagation();
      });
    </script>
  </body>
</html>